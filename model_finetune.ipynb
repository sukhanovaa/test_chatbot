{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A general plan\n",
    "* Explore metrics used to evaluate conversational flow\n",
    "* Choose an open-source model that \n",
    "    1. fits my hardware capacity\n",
    "    2. has nice metrics\n",
    "* Choose conversational datasets to finetune\n",
    "* Prepare said datasets\n",
    "* Add LoRA code - thanks to yandexdataschool for additional guidance!\n",
    "* Finetune the model (using huggingface trainer)\n",
    "\n",
    "...then wrap the model into a container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore metrics\n",
    "Naive, regarding interaction statistics\n",
    "* Length of conversation: how long (in user lines) lasts a chat on average.\n",
    "* Time between replies to the chatbot, which could indicate the level of a user's engagement. Requires analytics to establish thresholds.\n",
    "* Human feedback, as in\n",
    "    - \"Were you satisfied by the conversation? Y/N\" at the end of the conversation - does not give fine-grained information about what happened during the conversation that led to a particular assessment\n",
    "    - grade 1-10 - just as above. \n",
    "    - This is overall messy, but it makes sense for such feedback to be collected, then post-analyzed by assessors.\n",
    "* How often do users come back to chat again? Need users!\n",
    "* How often is a chat with a model abandoned at the start? Need users!\n",
    "\n",
    "\n",
    "Naive, based on text\n",
    "* repetition / fluency, as in N of distinct n-grams - the only quantifiable metric. However, it really is just a proxy metric for generation quality; does not measure the adequacy of the conversation...\n",
    "* perplexity on the user questions? - this is not about answers' quality at all; besides, I doubt that huge models have difficulties in this domain\n",
    "* overlap between a user's question and a model's answer - I think this is a bit outdated for LLM evaluation, since it used to be a problem around 2017-2020 maybe. Could make sense if we have enough time to check the LM's answer before outputting it to the user. I incorporated it, anyway. \n",
    "* F-measure/BLEU/etc. on questions with pre-defined answers? - might be good for tracking factual information, but the good chit-chat has nothing pre-defined a priori.\n",
    "* Embedding distance between the user's question and the model's answer - seems pretty much the same as the previous idea\n",
    "* % of negative user responses (\"no, that's not what I was talking about\"; \"that's a dumb response\"; \"bad bot\"); % of positive user responses (\"You're funny!\", \"Great, thanks\", \"you're right\")\n",
    "    - very hard to define 'negative', but theoretically it could be (embedding) cosine similarity to sets of responses similar to above; results in a problem of constructing such sets, extracting user responses from paragraphs, etc.\n",
    "    - metrics such as these are really very much user-dependent (what if a user is often ironic? what if they're displaying opinions far from a bot's training data distribution? what if a user is in a bad mood...)\n",
    "    - but __could be captured__ if reframed as an entailment task (LM-user answer pairs, entailment/contradiction/neutral; we're looking for contradictions; something like https://arxiv.org/abs/1904.03371 ?) or as a sentiment analysis task, but requires additional models\n",
    "\n",
    "I actually expect that interaction-based metrics per model are much more telling than the textual ones.\n",
    "\n",
    "I looked at several dialogue evaluation datasets, and found them either too specialized ([MultiWOZ](https://github.com/budzianowski/multiwoz/tree/master/data/MultiWOZ_2.2)) or too vague for usage in automatic evaluation (([OpenDialKG](https://github.com/facebookresearch/opendialkg/tree/main)) - this one looks good for fine-tuning, though!)\n",
    "\n",
    "There are attempts at building specialized metrics involving various aspects of quality, e.g. empathy: https://github.com/Sea94/ieval\n",
    "\n",
    "And we could always try and evaluate on some task that involves generating capabilities under a restriction, e.g. a narrowly defined task like summarization in terms of sentence compression. Unfortunately, in causal LMs, that involves heavy amount of prompting, and if a metric depends on a prompt engineer skill (while prompts are uncomparable across different models), it does not look pretty.\n",
    "\n",
    "I checked https://github.com/violet-zct/fairseq-detect-hallucination/ in order to see for myself how this 'hallucination' metric worked - this framework does not use metrics like ROUGE or BLEU. It is not defined for LMs, however.\n",
    "\n",
    "### To sum up\n",
    "This is a real headscratcher. Human evaluation, with an addition of user interaction-based numbers, should probably do the work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a model\n",
    "\n",
    "A recent causal LM that fits my memory is all I ask, so under 13B\n",
    "* OPT? Comes in flavours like < 1B, 1.3B, 2.7B, 6.7B\n",
    "* GPT-J? 6B\n",
    "* LLaMA? 7B\n",
    "\n",
    "I looked at https://weightwatcher.ai/leaderboard.html and https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard and compared the top models regarding their Alpha and Average, respectively. Frankly, these two metrics seem to be contradicting each other. \n",
    "\n",
    "Surprisingly, an OPT-1.3B model was pretty small, high in Alpha and decent in terms of Truthfulness, although other metrics were not as impressive. Alas, my RAM is limited, and so I could not build an image using anything really large.\n",
    "\n",
    "Since I haven't had any opinion based on experience, I decided to test the pipeline on a (really) small OPT. \n",
    "\n",
    "If I had enough time/memory, I'd switch to the fresh LLaMA-2 (7B) -- it demonstrates a good average on the leaderboard tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers datasets peft accelerate bitsandbytes sacremoses pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "# model_id = \"facebook/opt-1.3b\"\n",
    "model_id = 'facebook/opt-350m'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "# max_length is not set properly\n",
    "max_len = AutoConfig.from_pretrained(model_id).max_position_embeddings\n",
    "tokenizer.model_max_length = max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose datasets & prepare them\n",
    "\n",
    "Personally, I think that all dialogue corpora ought to be curated. As a source of data, Reddit probably contains most lively responses, but it is potentially unpredictable and should be tested first. I considered the following datasets:\n",
    "\n",
    "* ConvAI2/3 dataset - on the closer look, it has a deeper structure that is useful in RLHF or evaluation contexts\n",
    "* The NPS Chat Corpus - not in Huggingface Datasets, but potentially useful\n",
    "* Cornell Movie-Dialogs Corpus\n",
    "* HC3 (which also contains ChatGPT answers, but we won't need them)\n",
    "* and DailyDialogue corpus\n",
    "\n",
    "\n",
    "And then the problems started.\n",
    "\n",
    "- I haven't opened a PR yet, but the builder script for 'cornell_movie_dialog' is broken\n",
    "    \n",
    "    `y = load_dataset('cornell_movie_dialog')`\n",
    "- 'Hello-SimpleAI/HC3' is broken too\n",
    "    \n",
    "    `z = load_dataset('Hello-SimpleAI/HC3')`\n",
    "- The NPS Chat Corpus is a part of NLTK, and it's completely unusable because it is a loose collection of posts and not (somewhat coherent) dialogs. \n",
    "\n",
    "\n",
    "I was left with DailyDialogue and manually-processed HC3.\n",
    "\n",
    "By the way, these should've worked better if the data also contained prompts (like 'USER1 says '), in a manner in which the chatbot is prompted (see src/chatbot.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eed6cfa44d04c25838ebf3f505e7003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11118 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050f4746e19e403686266433fa8ebcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "# by the way, daily_dialogs is suddenly pre-tokenized in some places\n",
    "from sacremoses import MosesDetokenizer\n",
    "\n",
    "dd = load_dataset('daily_dialog') # ['dialog']\n",
    "detok = MosesDetokenizer('en')\n",
    "\n",
    "# I really admire this line in tokenization utils:\n",
    "#     if max_length is None and len(ids) > self.model_max_length and verbose: <some warning about how it's not going to use max_length>\n",
    "# why declaring it then?\n",
    "\n",
    "def process_daily_dialogs(examples):\n",
    "    temp = [[detok.detokenize(x.split()) for x in y] for y in examples['dialog']]\n",
    "    temp = [' | '.join(x) for x in temp]\n",
    "    examples = tokenizer(temp, max_length=tokenizer.model_max_length)\n",
    "    return examples\n",
    "\n",
    "dd['train'] = dd['train'].map(process_daily_dialogs, batched=True, remove_columns=[\"dialog\", 'act', 'emotion'])\n",
    "dd['test'] = dd['test'].map(process_daily_dialogs, batched=True, remove_columns=[\"dialog\", 'act', 'emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77769c504a054275a2c0f1f0a673ae0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21889 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef3518404de471680a370459e07177e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2433 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !wget https://huggingface.co/datasets/Hello-SimpleAI/HC3/resolve/main/all.jsonl\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def load_hc3():\n",
    "    with open(\"all.jsonl\") as inp:\n",
    "        data = pd.DataFrame.from_records([json.loads(line) for line in inp])\n",
    "    return data\n",
    "\n",
    "hc3 = Dataset.from_pandas(load_hc3())\n",
    "hc3 = hc3.train_test_split(test_size=0.1)\n",
    "\n",
    "def process_hc3(examples):\n",
    "    # This could have been done in pandas, I think...\n",
    "    pairs = []\n",
    "    for x, y in zip(examples['question'], examples['human_answers']):\n",
    "        x = [detok.detokenize(x.split())] * len(y)\n",
    "        y = [detok.detokenize(t.split()) for t in y]\n",
    "        pairs.extend([' | '.join(d) for d in zip(x, y)])\n",
    "    examples = tokenizer(pairs, max_length=tokenizer.model_max_length)\n",
    "    return examples\n",
    "    \n",
    "hc3['train'] = hc3['train'].map(process_hc3, batched=True, remove_columns=[\"question\", 'human_answers', 'chatgpt_answers', 'index', 'source'])\n",
    "hc3['test'] = hc3['test'].map(process_hc3, batched=True, remove_columns=[\"question\", 'human_answers', 'chatgpt_answers', 'index', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "data_train = concatenate_datasets([dd['train'], hc3['train']]) \n",
    "data_test = concatenate_datasets([dd['test'], hc3['test']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA\n",
    "\n",
    "I'll use one PEFT-LoRa example, because I don't really have a lot of time to look deeper than that. I suppose that Prefix Tuning could work better, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!export PYTORCH_ENABLE_MPS_FALLBACK=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForCausalLM were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Can't load back quantization without GPU \n",
    "# from peft import prepare_model_for_int8_training\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map={\"\":0})\n",
    "# model = prepare_model_for_int8_training(model)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map='cpu')  #load_in_8bit=True\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "config = LoraConfig(r=8, lora_alpha=32, target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"], \n",
    "                    lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "model = model.float()\n",
    "# model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.4723e+02,  1.5523e+03, -3.5968e+03,  8.8323e+02, -1.1636e+02,\n",
      "         5.8384e+02, -2.2802e+02,  2.1153e+02,  4.7491e+02,  1.7522e+03,\n",
      "         4.3498e+02,  6.0625e+02,  1.0186e+02,  1.8586e+02, -3.1153e+02,\n",
      "         2.0905e+02, -3.6086e-01, -1.0476e+03, -3.3628e+03, -7.7822e+01,\n",
      "        -5.2680e+03, -3.1091e+02,  1.5983e+02, -1.7921e+02, -5.0815e+02,\n",
      "         3.9251e+02, -1.9007e+03,  9.6294e+02, -2.5768e+02, -1.2473e+02,\n",
      "        -5.9086e+01, -1.4384e+02, -2.0451e+03, -2.6408e+03,  3.1167e+03,\n",
      "         9.2373e+01, -2.7629e+02,  2.1598e+03,  2.5048e+03,  1.6986e+00,\n",
      "        -5.5232e+02,  1.3826e+02, -2.6508e+02, -4.9032e+03,  3.4328e+02,\n",
      "         1.4574e+03, -2.2531e+02, -1.8587e+03, -2.6004e+02,  9.2003e+01,\n",
      "         1.6195e+02, -5.1665e+03, -3.5247e+03, -2.2519e+03, -9.1076e+01,\n",
      "        -7.3918e+02,  2.3497e+02, -2.7405e+02, -2.8799e+01,  4.6253e+02,\n",
      "        -1.8389e+02,  5.5446e+02, -1.2216e+02,  6.4612e+02,  1.0152e+03,\n",
      "        -4.5776e+02, -8.4575e+01,  3.5000e+03, -2.6323e+02, -5.5525e+02,\n",
      "         1.4173e+03, -4.6946e+01, -5.4229e+02,  3.0085e+01,  2.1708e+02,\n",
      "         8.0049e+02,  1.4454e+02,  1.2277e+03, -7.0715e+02, -7.3765e+02,\n",
      "         4.7212e+02,  5.5254e+02, -3.6532e+02,  3.8756e+02,  5.4765e+02,\n",
      "         4.3008e+02,  1.8179e+02, -7.9157e+01,  1.7971e+02,  1.4000e+02,\n",
      "        -1.8835e+02, -1.5316e+02, -1.4407e+02,  6.7651e+02, -1.9310e+01,\n",
      "         1.7880e+02,  2.6188e+02, -1.3358e+03, -3.3087e+03,  3.7383e+02,\n",
      "        -3.0136e+02, -1.4932e+03,  1.0583e+02, -3.2550e+02, -2.6039e+03,\n",
      "        -1.5704e+02,  3.8731e+02, -6.0334e+01, -1.3052e+03,  5.8875e+01,\n",
      "         6.7865e+01, -2.2445e+03,  7.7777e+01,  2.3156e+03,  2.3877e+02,\n",
      "        -3.8292e+03,  4.3819e+01,  4.0735e+03, -1.4084e+03, -2.0922e+02,\n",
      "        -1.4649e+02, -6.1023e+02, -1.6039e+02,  2.7288e+02,  1.4048e+02,\n",
      "        -6.8838e+02, -6.3966e+02, -2.5495e+02, -3.0860e+02,  6.7814e+01,\n",
      "         1.2982e+02,  2.4337e+02,  3.5241e+03, -2.5633e+02,  2.9279e+02,\n",
      "        -2.4831e+02, -3.5172e+02,  1.4051e+02, -4.5156e+01, -2.6705e+03,\n",
      "        -3.5484e+02, -2.1681e+02, -1.8767e+01,  7.7056e+01, -1.4774e+02,\n",
      "        -8.3791e+02, -6.0739e+02, -9.2022e+01, -3.6596e+02,  1.1314e+02,\n",
      "        -2.1603e+02,  2.8898e+02,  1.2490e+03, -5.2755e+03,  3.1164e+02,\n",
      "        -5.2225e+02,  4.9690e-01, -2.9694e+03,  1.4458e+02,  1.7367e+03,\n",
      "         1.2011e+02, -3.2594e+03,  8.6826e+02, -3.2283e+02, -1.1688e+02,\n",
      "        -2.6305e+03,  5.2238e+01, -3.0588e+02, -7.3189e+01, -2.7832e+03,\n",
      "         9.0571e+02, -2.1009e+02, -1.4767e+02,  7.1699e+01,  2.7526e+03,\n",
      "         3.8873e+02,  1.7878e+02, -3.1788e+01, -4.9627e+01,  7.1783e+02,\n",
      "        -1.2475e+03,  2.8552e+03, -2.0818e+02, -2.0434e+03,  1.7508e+02,\n",
      "        -1.1419e+02,  1.2931e+02,  1.4123e+03,  2.8616e+02,  8.3015e+02,\n",
      "         2.4199e+02,  1.2323e+02, -7.6766e+01, -1.8734e+02,  1.1283e+03,\n",
      "        -5.1063e+02,  1.1925e+02, -5.4972e+01,  1.3397e+03, -1.4314e+03,\n",
      "        -5.2562e+01, -5.4131e+02,  1.7959e+03,  3.3165e+03, -7.5196e+02,\n",
      "        -4.9280e+02, -3.6762e+02,  1.5399e+02,  8.9730e+02, -1.2180e+02,\n",
      "        -2.3707e+03,  1.3168e+02,  2.7843e+02,  8.3756e+02,  1.8904e+02,\n",
      "         5.9115e+02, -4.6892e+02,  2.1528e+02,  8.8593e+01, -3.4293e+01,\n",
      "        -1.7547e+03, -6.1788e+01, -7.2375e+02, -3.9602e+03, -5.3032e+02,\n",
      "         1.7461e+02, -8.5055e+02,  3.7278e+02,  1.8394e+02,  3.9800e+02,\n",
      "        -3.1655e+02, -1.4390e+01, -1.1331e+03, -2.2538e+03,  1.1382e+03,\n",
      "         2.4882e+02, -3.4804e+02,  3.6393e+02,  1.2024e+03,  1.8268e+02,\n",
      "         3.9054e+02,  2.0940e+02, -4.5663e+02,  9.0144e+02, -4.5580e+03,\n",
      "        -1.5838e+02, -1.8840e+02, -8.8241e+02,  3.1699e+03,  2.8921e+02,\n",
      "         1.8898e+03,  3.7022e+02,  3.7380e+03,  1.3852e+03, -3.5514e+02,\n",
      "         1.3540e+02,  8.6339e+01, -5.7963e+02,  1.2987e+02,  6.0719e+02,\n",
      "        -3.8579e+02, -6.1887e+02, -5.4851e+02,  1.8998e+02,  2.1472e+02,\n",
      "        -1.0931e+03, -1.7658e+02,  1.1315e+02, -1.9930e+02,  2.1086e+02,\n",
      "         4.5236e+01, -1.4388e+02, -1.1842e+03, -2.1506e+03,  8.0320e+01,\n",
      "        -5.0066e+02, -3.4871e+02, -5.9267e+01,  2.5120e+03, -1.3541e+03,\n",
      "         1.0512e+02,  1.3775e+02, -4.2198e+02,  2.2690e+02, -2.9274e+02,\n",
      "        -1.5041e+03,  1.6491e+02, -5.6524e+02, -9.2523e+01, -1.3915e+03,\n",
      "         3.0578e+02, -3.8125e+01,  1.2461e+02, -6.2439e+01, -3.8545e+02,\n",
      "         6.3713e+02, -1.5971e+03,  3.4043e+03, -1.1422e+03, -4.7744e+01,\n",
      "         4.3543e+03,  4.7069e+02,  6.5024e+02,  5.8687e+01,  2.3799e+03,\n",
      "        -1.5342e+02,  2.5390e+02, -9.6515e+01, -4.6877e+01,  2.4354e+03,\n",
      "         3.0865e+03,  1.5600e+03, -1.1394e+03,  5.6931e+03,  1.2195e+02,\n",
      "        -3.5365e+02,  6.5799e+02, -2.8142e+02, -7.5575e+02,  1.7821e+03,\n",
      "         6.3131e+00,  1.1934e+02, -2.2958e+01,  1.7962e+03,  1.0989e+03,\n",
      "        -8.7339e+01,  7.0902e+01,  1.9057e+01, -1.7090e+02, -2.1888e+01,\n",
      "        -3.3527e+02, -1.7590e+02, -1.6146e+02, -1.9038e+02,  4.8916e+02,\n",
      "        -1.8106e+03, -1.4812e+02,  7.9639e+01,  1.4489e+02, -5.6836e+02,\n",
      "        -7.5638e+01, -4.4250e+02, -1.0253e+03, -9.7142e+01, -3.8084e+02,\n",
      "         1.3314e+02,  6.9957e+02, -2.5280e+02, -1.1084e+02,  6.3060e+01,\n",
      "         7.7172e+01,  6.8601e+01,  1.6798e+01,  6.0913e+02, -2.5081e+02,\n",
      "         3.1742e+02, -4.1845e+02,  5.3672e+02, -3.4531e-01, -2.2466e+02,\n",
      "         8.9151e+02, -9.7227e+01,  2.7738e+02, -3.5323e+02, -5.7577e+03,\n",
      "        -4.4015e+02,  8.0226e+01, -6.7808e+01, -2.0558e+02,  9.4959e+01,\n",
      "         3.1617e+01,  8.5402e+02, -4.4893e+01,  8.9923e+01,  1.1236e+02,\n",
      "         2.8276e+03, -3.5337e+02, -2.0412e+03,  3.1715e+02, -1.5808e+02,\n",
      "         4.8014e+01, -2.2011e+02, -6.6262e+02,  2.6392e+00, -3.2567e+02,\n",
      "         3.3665e+02, -4.8474e+02,  3.8095e+02, -1.2475e+03, -1.9894e+02,\n",
      "         5.2371e+02, -3.4371e+03,  8.8688e+01,  1.5875e+02, -2.8054e+03,\n",
      "         1.2129e+02,  6.7906e+01, -2.8415e+01, -4.1549e+02, -8.6363e+02,\n",
      "         5.7163e+02, -1.7153e+02,  3.7899e+02, -2.9922e+02, -6.0545e+02,\n",
      "        -5.9942e+02,  1.0149e+03,  1.2414e+03,  1.8541e+02,  5.4379e+02,\n",
      "        -2.5904e+02, -4.3615e+02,  3.4254e+02, -1.0075e+03, -1.6553e+02,\n",
      "         6.1127e+02,  4.6681e+02,  9.7230e+00, -5.8114e+03, -8.5881e+02,\n",
      "         4.0835e+03, -3.6969e+02, -9.9457e+02, -1.6401e+03,  2.6021e+02,\n",
      "        -2.4766e+01,  8.8051e+01,  9.5109e+02,  2.4326e+02, -9.2962e+02,\n",
      "         2.5520e+02, -8.9750e+02, -6.6401e+01, -1.2903e+01, -1.2630e+03,\n",
      "        -8.3223e+01,  4.7937e+02,  1.8013e+03, -1.2440e+03,  1.8025e+03,\n",
      "        -7.4621e+02, -2.2166e+02, -2.5364e+02, -6.5769e+02,  2.2403e+03,\n",
      "         1.2664e+01, -7.9962e+02,  3.9051e+02,  8.0274e+01, -6.5718e+01,\n",
      "         6.6740e+02,  5.4157e+01,  8.6302e+02,  1.7860e+03,  4.7023e+02,\n",
      "        -2.6201e+02, -1.0227e+03, -1.4161e+02, -1.5222e+03,  3.2972e+03,\n",
      "        -3.1232e+02,  4.5010e+00,  3.6362e+03,  2.2214e+03, -1.4683e+01,\n",
      "        -4.0938e+02, -3.0121e+02,  1.1945e+03, -9.5126e+02,  1.3819e+02,\n",
      "        -2.3707e+02,  5.6552e+03, -2.2475e+01,  2.5764e+03, -4.3235e+03,\n",
      "        -1.8714e+03,  1.2996e+02, -1.6588e+03,  9.1960e+01, -3.8681e+03,\n",
      "        -4.5965e+01,  2.7434e+02,  1.0408e+03, -1.7632e+02, -8.6045e+02,\n",
      "        -5.1992e+02,  3.8544e+02,  1.8254e+03, -3.3028e+02, -2.0991e+02,\n",
      "        -9.6864e+02,  1.7390e+02,  2.1138e+03, -4.7655e+02,  5.1864e+02,\n",
      "        -1.3227e+02,  5.9439e+02,  8.4452e+02,  2.2609e+02, -3.1413e+01,\n",
      "         1.0948e+03, -5.0175e+03,  1.2257e+02,  3.1854e+02, -2.9032e+02,\n",
      "         1.7119e+03,  3.9987e+01,  8.0401e+02, -5.1615e+02, -3.3587e+03,\n",
      "         1.9026e+02,  3.5993e+02])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict()['base_model.model.lm_head.weight'].sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "loader = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa667450c2644faf88cb81d1264d22da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 12.7164, 'train_samples_per_second': 0.157, 'train_steps_per_second': 0.157, 'train_loss': 3.553908348083496, 'epoch': 0.0}\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=1,\n",
    "        auto_find_batch_size=False,\n",
    "        # warmup_steps=250,\n",
    "        # max_steps=5000,\n",
    "        warmup_steps=1,\n",
    "        max_steps=2,\n",
    "        learning_rate=2e-4,  # ?\n",
    "        no_cuda=True, \n",
    "        logging_steps=250,\n",
    "        output_dir=\"outputs\",\n",
    "        # optim=\"paged_adamw_8bit\"\n",
    "        optim='adamw_torch'\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_test,\n",
    "    args=args,\n",
    "    data_collator=loader\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model('weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForCausalLM were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "\n",
    "peft_config = PeftConfig.from_pretrained('weights')\n",
    "model = AutoModelForCausalLM.from_pretrained(peft_config.base_model_name_or_path,\n",
    "                                             # load_in_8bit=True, \n",
    "                                             device_map='cpu')\n",
    "model = PeftModel.from_pretrained(model, 'weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.4723e+02,  1.5523e+03, -3.5968e+03,  8.8323e+02, -1.1636e+02,\n",
      "         5.8384e+02, -2.2802e+02,  2.1153e+02,  4.7491e+02,  1.7522e+03,\n",
      "         4.3498e+02,  6.0625e+02,  1.0186e+02,  1.8586e+02, -3.1153e+02,\n",
      "         2.0905e+02, -3.6086e-01, -1.0476e+03, -3.3628e+03, -7.7822e+01,\n",
      "        -5.2680e+03, -3.1091e+02,  1.5983e+02, -1.7921e+02, -5.0815e+02,\n",
      "         3.9251e+02, -1.9007e+03,  9.6294e+02, -2.5768e+02, -1.2473e+02,\n",
      "        -5.9086e+01, -1.4384e+02, -2.0451e+03, -2.6408e+03,  3.1167e+03,\n",
      "         9.2373e+01, -2.7629e+02,  2.1598e+03,  2.5048e+03,  1.6986e+00,\n",
      "        -5.5232e+02,  1.3826e+02, -2.6508e+02, -4.9032e+03,  3.4328e+02,\n",
      "         1.4574e+03, -2.2531e+02, -1.8587e+03, -2.6004e+02,  9.2003e+01,\n",
      "         1.6195e+02, -5.1665e+03, -3.5247e+03, -2.2519e+03, -9.1076e+01,\n",
      "        -7.3918e+02,  2.3497e+02, -2.7405e+02, -2.8799e+01,  4.6253e+02,\n",
      "        -1.8389e+02,  5.5446e+02, -1.2216e+02,  6.4612e+02,  1.0152e+03,\n",
      "        -4.5776e+02, -8.4575e+01,  3.5000e+03, -2.6323e+02, -5.5525e+02,\n",
      "         1.4173e+03, -4.6946e+01, -5.4229e+02,  3.0085e+01,  2.1708e+02,\n",
      "         8.0049e+02,  1.4454e+02,  1.2277e+03, -7.0715e+02, -7.3765e+02,\n",
      "         4.7212e+02,  5.5254e+02, -3.6532e+02,  3.8756e+02,  5.4765e+02,\n",
      "         4.3008e+02,  1.8179e+02, -7.9157e+01,  1.7971e+02,  1.4000e+02,\n",
      "        -1.8835e+02, -1.5316e+02, -1.4407e+02,  6.7651e+02, -1.9310e+01,\n",
      "         1.7880e+02,  2.6188e+02, -1.3358e+03, -3.3087e+03,  3.7383e+02,\n",
      "        -3.0136e+02, -1.4932e+03,  1.0583e+02, -3.2550e+02, -2.6039e+03,\n",
      "        -1.5704e+02,  3.8731e+02, -6.0334e+01, -1.3052e+03,  5.8875e+01,\n",
      "         6.7865e+01, -2.2445e+03,  7.7777e+01,  2.3156e+03,  2.3877e+02,\n",
      "        -3.8292e+03,  4.3819e+01,  4.0735e+03, -1.4084e+03, -2.0922e+02,\n",
      "        -1.4649e+02, -6.1023e+02, -1.6039e+02,  2.7288e+02,  1.4048e+02,\n",
      "        -6.8838e+02, -6.3966e+02, -2.5495e+02, -3.0860e+02,  6.7814e+01,\n",
      "         1.2982e+02,  2.4337e+02,  3.5241e+03, -2.5633e+02,  2.9279e+02,\n",
      "        -2.4831e+02, -3.5172e+02,  1.4051e+02, -4.5156e+01, -2.6705e+03,\n",
      "        -3.5484e+02, -2.1681e+02, -1.8767e+01,  7.7056e+01, -1.4774e+02,\n",
      "        -8.3791e+02, -6.0739e+02, -9.2022e+01, -3.6596e+02,  1.1314e+02,\n",
      "        -2.1603e+02,  2.8898e+02,  1.2490e+03, -5.2755e+03,  3.1164e+02,\n",
      "        -5.2225e+02,  4.9690e-01, -2.9694e+03,  1.4458e+02,  1.7367e+03,\n",
      "         1.2011e+02, -3.2594e+03,  8.6826e+02, -3.2283e+02, -1.1688e+02,\n",
      "        -2.6305e+03,  5.2238e+01, -3.0588e+02, -7.3189e+01, -2.7832e+03,\n",
      "         9.0571e+02, -2.1009e+02, -1.4767e+02,  7.1699e+01,  2.7526e+03,\n",
      "         3.8873e+02,  1.7878e+02, -3.1788e+01, -4.9627e+01,  7.1783e+02,\n",
      "        -1.2475e+03,  2.8552e+03, -2.0818e+02, -2.0434e+03,  1.7508e+02,\n",
      "        -1.1419e+02,  1.2931e+02,  1.4123e+03,  2.8616e+02,  8.3015e+02,\n",
      "         2.4199e+02,  1.2323e+02, -7.6766e+01, -1.8734e+02,  1.1283e+03,\n",
      "        -5.1063e+02,  1.1925e+02, -5.4972e+01,  1.3397e+03, -1.4314e+03,\n",
      "        -5.2562e+01, -5.4131e+02,  1.7959e+03,  3.3165e+03, -7.5196e+02,\n",
      "        -4.9280e+02, -3.6762e+02,  1.5399e+02,  8.9730e+02, -1.2180e+02,\n",
      "        -2.3707e+03,  1.3168e+02,  2.7843e+02,  8.3756e+02,  1.8904e+02,\n",
      "         5.9115e+02, -4.6892e+02,  2.1528e+02,  8.8593e+01, -3.4293e+01,\n",
      "        -1.7547e+03, -6.1788e+01, -7.2375e+02, -3.9602e+03, -5.3032e+02,\n",
      "         1.7461e+02, -8.5055e+02,  3.7278e+02,  1.8394e+02,  3.9800e+02,\n",
      "        -3.1655e+02, -1.4390e+01, -1.1331e+03, -2.2538e+03,  1.1382e+03,\n",
      "         2.4882e+02, -3.4804e+02,  3.6393e+02,  1.2024e+03,  1.8268e+02,\n",
      "         3.9054e+02,  2.0940e+02, -4.5663e+02,  9.0144e+02, -4.5580e+03,\n",
      "        -1.5838e+02, -1.8840e+02, -8.8241e+02,  3.1699e+03,  2.8921e+02,\n",
      "         1.8898e+03,  3.7022e+02,  3.7380e+03,  1.3852e+03, -3.5514e+02,\n",
      "         1.3540e+02,  8.6339e+01, -5.7963e+02,  1.2987e+02,  6.0719e+02,\n",
      "        -3.8579e+02, -6.1887e+02, -5.4851e+02,  1.8998e+02,  2.1472e+02,\n",
      "        -1.0931e+03, -1.7658e+02,  1.1315e+02, -1.9930e+02,  2.1086e+02,\n",
      "         4.5236e+01, -1.4388e+02, -1.1842e+03, -2.1506e+03,  8.0320e+01,\n",
      "        -5.0066e+02, -3.4871e+02, -5.9267e+01,  2.5120e+03, -1.3541e+03,\n",
      "         1.0512e+02,  1.3775e+02, -4.2198e+02,  2.2690e+02, -2.9274e+02,\n",
      "        -1.5041e+03,  1.6491e+02, -5.6524e+02, -9.2523e+01, -1.3915e+03,\n",
      "         3.0578e+02, -3.8125e+01,  1.2461e+02, -6.2439e+01, -3.8545e+02,\n",
      "         6.3713e+02, -1.5971e+03,  3.4043e+03, -1.1422e+03, -4.7744e+01,\n",
      "         4.3543e+03,  4.7069e+02,  6.5024e+02,  5.8687e+01,  2.3799e+03,\n",
      "        -1.5342e+02,  2.5390e+02, -9.6515e+01, -4.6877e+01,  2.4354e+03,\n",
      "         3.0865e+03,  1.5600e+03, -1.1394e+03,  5.6931e+03,  1.2195e+02,\n",
      "        -3.5365e+02,  6.5799e+02, -2.8142e+02, -7.5575e+02,  1.7821e+03,\n",
      "         6.3131e+00,  1.1934e+02, -2.2958e+01,  1.7962e+03,  1.0989e+03,\n",
      "        -8.7339e+01,  7.0902e+01,  1.9057e+01, -1.7090e+02, -2.1888e+01,\n",
      "        -3.3527e+02, -1.7590e+02, -1.6146e+02, -1.9038e+02,  4.8916e+02,\n",
      "        -1.8106e+03, -1.4812e+02,  7.9639e+01,  1.4489e+02, -5.6836e+02,\n",
      "        -7.5638e+01, -4.4250e+02, -1.0253e+03, -9.7142e+01, -3.8084e+02,\n",
      "         1.3314e+02,  6.9957e+02, -2.5280e+02, -1.1084e+02,  6.3060e+01,\n",
      "         7.7172e+01,  6.8601e+01,  1.6798e+01,  6.0913e+02, -2.5081e+02,\n",
      "         3.1742e+02, -4.1845e+02,  5.3672e+02, -3.4531e-01, -2.2466e+02,\n",
      "         8.9151e+02, -9.7227e+01,  2.7738e+02, -3.5323e+02, -5.7577e+03,\n",
      "        -4.4015e+02,  8.0226e+01, -6.7808e+01, -2.0558e+02,  9.4959e+01,\n",
      "         3.1617e+01,  8.5402e+02, -4.4893e+01,  8.9923e+01,  1.1236e+02,\n",
      "         2.8276e+03, -3.5337e+02, -2.0412e+03,  3.1715e+02, -1.5808e+02,\n",
      "         4.8014e+01, -2.2011e+02, -6.6262e+02,  2.6392e+00, -3.2567e+02,\n",
      "         3.3665e+02, -4.8474e+02,  3.8095e+02, -1.2475e+03, -1.9894e+02,\n",
      "         5.2371e+02, -3.4371e+03,  8.8688e+01,  1.5875e+02, -2.8054e+03,\n",
      "         1.2129e+02,  6.7906e+01, -2.8415e+01, -4.1549e+02, -8.6363e+02,\n",
      "         5.7163e+02, -1.7153e+02,  3.7899e+02, -2.9922e+02, -6.0545e+02,\n",
      "        -5.9942e+02,  1.0149e+03,  1.2414e+03,  1.8541e+02,  5.4379e+02,\n",
      "        -2.5904e+02, -4.3615e+02,  3.4254e+02, -1.0075e+03, -1.6553e+02,\n",
      "         6.1127e+02,  4.6681e+02,  9.7230e+00, -5.8114e+03, -8.5881e+02,\n",
      "         4.0835e+03, -3.6969e+02, -9.9457e+02, -1.6401e+03,  2.6021e+02,\n",
      "        -2.4766e+01,  8.8051e+01,  9.5109e+02,  2.4326e+02, -9.2962e+02,\n",
      "         2.5520e+02, -8.9750e+02, -6.6401e+01, -1.2903e+01, -1.2630e+03,\n",
      "        -8.3223e+01,  4.7937e+02,  1.8013e+03, -1.2440e+03,  1.8025e+03,\n",
      "        -7.4621e+02, -2.2166e+02, -2.5364e+02, -6.5769e+02,  2.2403e+03,\n",
      "         1.2664e+01, -7.9962e+02,  3.9051e+02,  8.0274e+01, -6.5718e+01,\n",
      "         6.6740e+02,  5.4157e+01,  8.6302e+02,  1.7860e+03,  4.7023e+02,\n",
      "        -2.6201e+02, -1.0227e+03, -1.4161e+02, -1.5222e+03,  3.2972e+03,\n",
      "        -3.1232e+02,  4.5010e+00,  3.6362e+03,  2.2214e+03, -1.4683e+01,\n",
      "        -4.0938e+02, -3.0121e+02,  1.1945e+03, -9.5126e+02,  1.3819e+02,\n",
      "        -2.3707e+02,  5.6552e+03, -2.2475e+01,  2.5764e+03, -4.3235e+03,\n",
      "        -1.8714e+03,  1.2996e+02, -1.6588e+03,  9.1960e+01, -3.8681e+03,\n",
      "        -4.5965e+01,  2.7434e+02,  1.0408e+03, -1.7632e+02, -8.6045e+02,\n",
      "        -5.1992e+02,  3.8544e+02,  1.8254e+03, -3.3028e+02, -2.0991e+02,\n",
      "        -9.6864e+02,  1.7390e+02,  2.1138e+03, -4.7655e+02,  5.1864e+02,\n",
      "        -1.3227e+02,  5.9439e+02,  8.4452e+02,  2.2609e+02, -3.1413e+01,\n",
      "         1.0948e+03, -5.0175e+03,  1.2257e+02,  3.1854e+02, -2.9032e+02,\n",
      "         1.7119e+03,  3.9987e+01,  8.0401e+02, -5.1615e+02, -3.3587e+03,\n",
      "         1.9026e+02,  3.5993e+02])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict()['base_model.model.lm_head.weight'].sum(axis=0))  # hmmm... something fishy, OPT-1.3B didn't have this warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
